{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9830163b",
   "metadata": {},
   "source": [
    "###  ML-Modell\n",
    "\n",
    "Dieser Prozess kann wie folgt zusammengefasst werden:\n",
    "\n",
    "1. Metrik wählen \n",
    "2. Systematisches Testen einer Reihe verschiedener Algorithmen in ihrem Datensatz.(Kreuzvalidierungsverfahren'StratifiedKFold')\n",
    "3. Hyperparameter-Tuning (Randomsearch, Bayessche_Optimierung )\n",
    "4. Select Features-Filter \n",
    "5. Ergbnisse präsentieren (Precision-Recall-Metrik und F_1)\n",
    "\n",
    "\n",
    "Dieses Problem ist eine typische Klassifikationsaufgabe, deswegen habe ich mich für vier Klassifikation Modellen ausgesucht.\n",
    "\n",
    "1. Logistic Regression\n",
    "2. Support Vector Machine (SVM)\n",
    "3. KNeighborsClassifier\n",
    "4. RandomForestClassifier\n",
    "\n",
    "Die Bankabwanderung sollte unter 25 % liegen, daher ein Modell, das besagt „Niemand wird abwandern“, muss zu 75 % genau sein. Ich konzentriere mich auf alle Abwanderungen, die das Modell korrekt identifiziert und der Prozentsatz der identifizierten Abwanderung, der tatsächlich zur Abwanderung führt. \n",
    "\n",
    "\n",
    "In diesem Fall handelt sich um eine unausgewogene Klassifizierung, deswegen habe ich mich für die Metriken Präzision, Recall und F_1 entschieden. \n",
    "\n",
    "Präzision = TruePositives / (TruePositives + FalsePositives)\n",
    "Recall = TruePositives / (TruePositives + FalseNegatives)\n",
    "\n",
    "Diese Metriken werten FalsePositives aus, die zu unnötigen und kostspieligen Bemühungen zur Vermeidung von Abwanderungen führen, und FalseNegatives, die dazu führen, dass Kunden aus dem Unternehmen abwandern, ohne identifiziert zu werden.\n",
    "\n",
    "Die Leistung eines Modells kann durch einen einzigen Wert zusammengefasst werden, der sowohl die Präzision als auch den Recall mittelt, der als F-Maß bezeichnet wird. Die Maximierung des F-Measure maximiert sowohl die Präzision als auch den Recall \n",
    "gleichzeitig.\n",
    "\n",
    "\n",
    "Der **F1-Score** ist eine Metrik, die die Genauigkeit zu erfassen versucht, wenn Klassen unausgeglichen sind, indem sie sich auf die Präzision positiver Vorhersagen und tatsächlich positiver Datensatzeinträge konzentriert. Sie gibt an, wie genau das Modell relevante Ergebnisse erfasst. Die Metrik versucht, Recall und Präzision auszugleichen, um im Idealfall eine mittlere Position zwischen beiden zu finden. Je unausgeglichener ein Datensatz ist, desto geringer ist voraussichtlich der F1-Score, selbst bei gleicher Gesamtgenauigkeit.\n",
    "\n",
    "Wenn der F1-Wert hoch ist, sind auch alle anderen Bewertungsmetriken hoch. Wenn der Wert niedrig ist, bedeutet das, dass sie eine weitere Analyse durchführen müssen. Wenn aber der Score sehr hoch ist oder der Holdout-Score wesentlich niedriger als der Kreuzvalidierungs-Score ist, könnte dies ein Anzeichen für Datenlecks sein.\n",
    "\n",
    "F-Maß = (2 * Präzision * Recall) / (Präzision + Recall)\n",
    "\n",
    "StratifiedKFold..?\n",
    "\n",
    "\n",
    "#### Das beste Baseline-Modell finden\n",
    "Die Idee ist den besten Algorithmus zu finden, der am besten auf als Basismodell funktioniert, das heißt ohne optimieren, und diesen auszuwählen, um ihn durch Hyperparameter-Tuning zu verbessern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5b92a81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from skopt import gp_minimize,dummy_minimize\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, SelectPercentile\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6baa037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install scikit-optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6fb0baf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skopt 0.9.0\n"
     ]
    }
   ],
   "source": [
    "import skopt\n",
    "print('skopt %s' % skopt.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4174c771",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('churn_model_clear.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6f988fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9995, 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fdef3f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "      <th>France</th>\n",
       "      <th>Spain</th>\n",
       "      <th>Germany</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.506735</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.310811</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.334031</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.562709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.636357</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.569654</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.283784</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.337838</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.500246</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.395400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.351351</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.453394</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.748797</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.432432</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.050261</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.148649</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.458540</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.596733</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.351351</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.566170</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.374680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.121622</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.536488</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.358605</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore       Age  Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
       "0          0.5  0.324324     0.2  0.000000       0.000000        1.0   \n",
       "1          0.5  0.310811     0.1  0.334031       0.000000        0.0   \n",
       "2          0.5  0.324324     0.8  0.636357       0.666667        1.0   \n",
       "3          0.5  0.283784     0.1  0.000000       0.333333        0.0   \n",
       "4          1.0  0.337838     0.2  0.500246       0.000000        1.0   \n",
       "5          0.5  0.351351     0.8  0.453394       0.333333        1.0   \n",
       "6          1.0  0.432432     0.7  0.000000       0.333333        1.0   \n",
       "7          0.0  0.148649     0.4  0.458540       1.000000        1.0   \n",
       "8          0.5  0.351351     0.4  0.566170       0.333333        0.0   \n",
       "9          0.5  0.121622     0.2  0.536488       0.000000        1.0   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Female  Male  France  Spain  \\\n",
       "0             1.0         0.506735     1.0     1.0   0.0     1.0    0.0   \n",
       "1             1.0         0.562709     0.0     1.0   0.0     0.0    1.0   \n",
       "2             0.0         0.569654     1.0     1.0   0.0     1.0    0.0   \n",
       "3             0.0         0.469120     0.0     1.0   0.0     1.0    0.0   \n",
       "4             1.0         0.395400     0.0     1.0   0.0     0.0    1.0   \n",
       "5             0.0         0.748797     1.0     0.0   1.0     0.0    1.0   \n",
       "6             1.0         0.050261     0.0     0.0   1.0     1.0    0.0   \n",
       "7             0.0         0.596733     1.0     1.0   0.0     0.0    0.0   \n",
       "8             1.0         0.374680     0.0     0.0   1.0     1.0    0.0   \n",
       "9             1.0         0.358605     0.0     0.0   1.0     1.0    0.0   \n",
       "\n",
       "   Germany  \n",
       "0      0.0  \n",
       "1      0.0  \n",
       "2      0.0  \n",
       "3      0.0  \n",
       "4      0.0  \n",
       "5      0.0  \n",
       "6      0.0  \n",
       "7      1.0  \n",
       "8      0.0  \n",
       "9      0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c28d41a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n",
    "       'IsActiveMember', 'EstimatedSalary','Female', 'Male',\n",
    "       'France', 'Spain', 'Germany']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7644d28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[variable]\n",
    "y = df['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54c637c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid , y_train, y_valid = train_test_split( X, y, test_size=0.33, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddcd71f",
   "metadata": {},
   "source": [
    "Mit den Methoden **GetBaseModel** und **ModelEvaluation** werden verschiedene Modelle verglichen.\n",
    "StratifiedKFold ?cross_val_score?\n",
    "\n",
    "In der Methode **ModelEvaluation** wird die Leistung einzelne Modellen durch die Technik Cross-Validation validiert.\n",
    "Diese Technik besteht aus der Trennung der Daten in verschiedenen K-Fold (Falten). Die Teile werden für Training und Test verwendet. Die Daten für das Training wird immer anders sein als für den Test.\n",
    "\n",
    "* Wenn die Daten sehr ähnliche Sätze sind, wird die tatsächliche Leistung von Modell maskiert\n",
    "* Durch Training und Testen mit allen aus den verfügbaren Daten wird das Modell zuverlässiger\n",
    "* Aussagekräftige Modellperformance auf Datensätzen mit Balance-Problemen \n",
    "* Identifizierung von Overfitting\n",
    "* Testen der Robustheit des Modell\n",
    "* Kreuzvalidierung löst das Varianzproblem in Daten.\n",
    "<br>.\n",
    "!['hallo'](bild/cross.png)\n",
    "<br>.\n",
    "   \n",
    "   \n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Das Modell mit dem besten Scoring wird dann als Baseline benutz. Das beste Modell war der RandomForestClassifier mit einem Scoring(f1_weighted) von **0.843742** und eine Varianz **0.013131**.\n",
    "Bei der Methode **ModelEvaluation** werden die Daten mit einem Stratified Kreuzvalidierungsverfahren trainiert. Das ist wichtig, weil die Daten unbalanciert sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "93076b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetBaseModels():\n",
    "    baseModels = []\n",
    "    baseModels.append(('KNeighborsClassifier'  , KNeighborsClassifier()))\n",
    "    baseModels.append(('RandomForestClassifier'   , RandomForestClassifier()))\n",
    "    baseModels.append(('SVC' , SVC(kernel='linear',random_state=SEED)))\n",
    "    baseModels.append(('KNeighborsClassifier',  KNeighborsClassifier()))\n",
    "    \n",
    "       \n",
    "    return baseModels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "004a53ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ModelEvaluation(X_train, y_train,models):\n",
    "    # define number of folds and evaluation metric\n",
    "    num_folds = 10\n",
    "    scoring = \"f1_weighted\" #This is suitable for imbalanced classes\n",
    "\n",
    "    results = []\n",
    "    names = []\n",
    "    for name, model in models:\n",
    "       # kfold = StratifiedKFold(n_splits=num_folds, random_state=SEED, shuffle = True)\n",
    "        kfold = RepeatedStratifiedKFold(n_splits=num_folds, n_repeats=10, random_state=SEED)\n",
    "        cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring, n_jobs = -1)\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "        print(msg)\n",
    "        \n",
    "    return names, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "78a0c948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier: 0.775486 (0.015307)\n",
      "RandomForestClassifier: 0.844653 (0.014260)\n",
      "SVC: 0.706481 (0.001513)\n",
      "KNeighborsClassifier: 0.775486 (0.015307)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['KNeighborsClassifier',\n",
       "  'RandomForestClassifier',\n",
       "  'SVC',\n",
       "  'KNeighborsClassifier'],\n",
       " [array([0.77879805, 0.77879805, 0.77687772, 0.78012965, 0.78202312,\n",
       "         0.79691971, 0.77556376, 0.76379435, 0.75431839, 0.76615847,\n",
       "         0.76855897, 0.79036298, 0.76314388, 0.7486344 , 0.77102545,\n",
       "         0.81251059, 0.76234205, 0.79480361, 0.75253924, 0.81030979,\n",
       "         0.74131805, 0.76545588, 0.76930592, 0.76991329, 0.78636213,\n",
       "         0.79993778, 0.77176   , 0.75801715, 0.78209018, 0.79371421,\n",
       "         0.76891685, 0.76545588, 0.80000957, 0.76176846, 0.79036298,\n",
       "         0.76748778, 0.77337417, 0.78692762, 0.75915231, 0.7607827 ,\n",
       "         0.76916348, 0.7962513 , 0.78232868, 0.77476706, 0.77493439,\n",
       "         0.79679159, 0.76980392, 0.78131373, 0.75431839, 0.7620509 ,\n",
       "         0.76730704, 0.78646747, 0.76385838, 0.78639437, 0.75349132,\n",
       "         0.78907441, 0.79696013, 0.75751471, 0.78782465, 0.77067302,\n",
       "         0.76558039, 0.76558039, 0.77476706, 0.77664723, 0.77476706,\n",
       "         0.76980392, 0.79459161, 0.79063466, 0.76148381, 0.78199781,\n",
       "         0.7566902 , 0.7602635 , 0.79405882, 0.79012936, 0.76228384,\n",
       "         0.76894664, 0.74220206, 0.80655568, 0.77252781, 0.79569272,\n",
       "         0.76930592, 0.79816788, 0.75901412, 0.76545588, 0.77275602,\n",
       "         0.76342898, 0.76776182, 0.79103332, 0.7754277 , 0.78180285,\n",
       "         0.75001042, 0.80064732, 0.8055    , 0.77076953, 0.78636213,\n",
       "         0.76980392, 0.76986623, 0.77120493, 0.76432309, 0.78978048]),\n",
       "  array([0.86949635, 0.84792683, 0.84373887, 0.84494792, 0.81449918,\n",
       "         0.83160944, 0.8299247 , 0.83806499, 0.82869378, 0.83862176,\n",
       "         0.82626742, 0.81025435, 0.8693644 , 0.83116401, 0.83941034,\n",
       "         0.84530159, 0.8628425 , 0.85743199, 0.84680998, 0.85898394,\n",
       "         0.82771571, 0.8693644 , 0.85269053, 0.83257736, 0.85048549,\n",
       "         0.86382278, 0.83873781, 0.82178571, 0.83776405, 0.84898937,\n",
       "         0.86587333, 0.83901304, 0.82141585, 0.84277735, 0.8548924 ,\n",
       "         0.85406151, 0.86633929, 0.86607039, 0.81404576, 0.83155562,\n",
       "         0.81726004, 0.84712856, 0.8616077 , 0.84810889, 0.83601064,\n",
       "         0.84420433, 0.8463836 , 0.85298086, 0.83901884, 0.8360598 ,\n",
       "         0.83815812, 0.85693985, 0.85936009, 0.83410294, 0.82962457,\n",
       "         0.86253229, 0.85520089, 0.83292411, 0.8360598 , 0.84554358,\n",
       "         0.8516085 , 0.82489271, 0.84031556, 0.85710448, 0.84289879,\n",
       "         0.85513736, 0.87244166, 0.84420433, 0.85453795, 0.83258141,\n",
       "         0.83982353, 0.84373887, 0.83298937, 0.84723462, 0.85932711,\n",
       "         0.86382278, 0.83590284, 0.86926987, 0.83494256, 0.84035428,\n",
       "         0.83109902, 0.85824648, 0.83471259, 0.84829394, 0.82699661,\n",
       "         0.8440625 , 0.84304383, 0.8507296 , 0.87193171, 0.83646095,\n",
       "         0.81191346, 0.8672619 , 0.84931963, 0.85602307, 0.85269053,\n",
       "         0.84721989, 0.84096872, 0.8408973 , 0.85677677, 0.83901884]),\n",
       "  array([0.70765647, 0.70765647, 0.70765647, 0.70765647, 0.70765647,\n",
       "         0.70420613, 0.70420613, 0.70420613, 0.70695567, 0.70695567,\n",
       "         0.70765647, 0.70765647, 0.70765647, 0.70765647, 0.70765647,\n",
       "         0.70420613, 0.70420613, 0.70420613, 0.70695567, 0.70695567,\n",
       "         0.70765647, 0.70765647, 0.70765647, 0.70765647, 0.70765647,\n",
       "         0.70420613, 0.70420613, 0.70420613, 0.70695567, 0.70695567,\n",
       "         0.70765647, 0.70765647, 0.70765647, 0.70765647, 0.70765647,\n",
       "         0.70420613, 0.70420613, 0.70420613, 0.70695567, 0.70695567,\n",
       "         0.70765647, 0.70765647, 0.70765647, 0.70765647, 0.70765647,\n",
       "         0.70420613, 0.70420613, 0.70420613, 0.70695567, 0.70695567,\n",
       "         0.70765647, 0.70765647, 0.70765647, 0.70765647, 0.70765647,\n",
       "         0.70420613, 0.70420613, 0.70420613, 0.70695567, 0.70695567,\n",
       "         0.70765647, 0.70765647, 0.70765647, 0.70765647, 0.70765647,\n",
       "         0.70420613, 0.70420613, 0.70420613, 0.70695567, 0.70695567,\n",
       "         0.70765647, 0.70765647, 0.70765647, 0.70765647, 0.70765647,\n",
       "         0.70420613, 0.70420613, 0.70420613, 0.70695567, 0.70695567,\n",
       "         0.70765647, 0.70765647, 0.70765647, 0.70765647, 0.70765647,\n",
       "         0.70420613, 0.70420613, 0.70420613, 0.70695567, 0.70695567,\n",
       "         0.70765647, 0.70765647, 0.70765647, 0.70765647, 0.70765647,\n",
       "         0.70420613, 0.70420613, 0.70420613, 0.70695567, 0.70695567]),\n",
       "  array([0.77879805, 0.77879805, 0.77687772, 0.78012965, 0.78202312,\n",
       "         0.79691971, 0.77556376, 0.76379435, 0.75431839, 0.76615847,\n",
       "         0.76855897, 0.79036298, 0.76314388, 0.7486344 , 0.77102545,\n",
       "         0.81251059, 0.76234205, 0.79480361, 0.75253924, 0.81030979,\n",
       "         0.74131805, 0.76545588, 0.76930592, 0.76991329, 0.78636213,\n",
       "         0.79993778, 0.77176   , 0.75801715, 0.78209018, 0.79371421,\n",
       "         0.76891685, 0.76545588, 0.80000957, 0.76176846, 0.79036298,\n",
       "         0.76748778, 0.77337417, 0.78692762, 0.75915231, 0.7607827 ,\n",
       "         0.76916348, 0.7962513 , 0.78232868, 0.77476706, 0.77493439,\n",
       "         0.79679159, 0.76980392, 0.78131373, 0.75431839, 0.7620509 ,\n",
       "         0.76730704, 0.78646747, 0.76385838, 0.78639437, 0.75349132,\n",
       "         0.78907441, 0.79696013, 0.75751471, 0.78782465, 0.77067302,\n",
       "         0.76558039, 0.76558039, 0.77476706, 0.77664723, 0.77476706,\n",
       "         0.76980392, 0.79459161, 0.79063466, 0.76148381, 0.78199781,\n",
       "         0.7566902 , 0.7602635 , 0.79405882, 0.79012936, 0.76228384,\n",
       "         0.76894664, 0.74220206, 0.80655568, 0.77252781, 0.79569272,\n",
       "         0.76930592, 0.79816788, 0.75901412, 0.76545588, 0.77275602,\n",
       "         0.76342898, 0.76776182, 0.79103332, 0.7754277 , 0.78180285,\n",
       "         0.75001042, 0.80064732, 0.8055    , 0.77076953, 0.78636213,\n",
       "         0.76980392, 0.76986623, 0.77120493, 0.76432309, 0.78978048])])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = GetBaseModels()\n",
    "ModelEvaluation(X_train, y_train, models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff17ccc9",
   "metadata": {},
   "source": [
    "Nachdem die Baseline festgestellt wurde, werden die Hyperparameter gesucht. Ich habe zwei Techniken RandomSearch und \n",
    "Bayes'sche Optimierung angewandet. \n",
    "\n",
    "1. Die **RandomizedSearchCV** ist ein Ansatz zur Parameterabstimmung, bei dem Algorithmusparameter aus einer zufälligen \n",
    "Verteilung für eine feste Anzahl von Iterationen abgetastet werden. Für jede gewählte Kombination \n",
    "von Parametern wird ein Modell konstruiert und bewertet. Sie können mit der RandomizedSearchCV \n",
    "eine zufällige Suche nach Algorithmusparametern durchführen.\n",
    "\n",
    "\n",
    "2. Die **Bayes'sche Optimierung** bietet eine prinzipielle Technik, die auf dem Bayes-Theorem basiert, um eine Suche nach einem globalen Optimierungsproblem zu steuern, das effizient und effektiv ist. Es funktioniert durch den Aufbau eines probabilistischen Modells der Zielfunktion, das als Ersatzfunktion bezeichnet wird, das dann effizient mit einer Erfassungsfunktion durchsucht wird, bevor Kandidatenstichproben zur Bewertung anhand der realen Zielfunktion ausgewählt werden.\n",
    "\n",
    "Um die beiden Techniken zu implentiren werde ich die Scikit-Optimize-Bibliothek benutzen. Die Scikit-Optimize-Bibliothek ist eine Open-Source-Python-Bibliothek, die eine Implementierung der Bayes'schen Optimierung  und RandomSearch bereitstellt, mit der die Hyperparameter von Machine Learning-Modellen aus der scikit-Learn Python-Bibliothek optimiert werden können.\n",
    "\n",
    "Zuerst habe ich  einen Suchraum definiert. In diesem Fall sind dies die Hyperparameter des Modells, das wir optimieren möchten, und der Umfang oder Bereich jedes Hyperparameters.\n",
    "\n",
    "Ich habe dann eine Funktion definiert, die vom Suchvorgang aufgerufen wird. Dies ist eine Funktion, die später von der Optimierungsprozedur erwartet wird und ein Modell und einen Satz spezifischer Hyperparameter für das Modell verwendet, es auswertet und eine Bewertung für den Satz von Hyperparametern zurückgibt.\n",
    "\n",
    "Als nächstes wurde die Suche ausgeführt, indem  die Funktion **gp_minimize()** und **dummy_minimize()** aufrufen und den Namen der aufzurufenden Funktion übergeben, um jedes Modell und den zu optimierenden Suchraum auszuwerten.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "74233baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def treinar_modelo(params):\n",
    "    n_estimators = params[0]\n",
    "    max_features = params[1]\n",
    "    max_depth = params[2]\n",
    "    min_samples_leaf = params[3]\n",
    "    bootstrap = params[4]\n",
    "    \n",
    "    print(params, '\\n')\n",
    "    \n",
    "    mdl = RandomForestClassifier(n_estimators= n_estimators, max_features=max_features,  max_depth= max_depth,\n",
    "                        min_samples_leaf=min_samples_leaf,  bootstrap=bootstrap, random_state=SEED,  class_weight='balanced')\n",
    "    mdl.fit(X_train, y_train)\n",
    "\n",
    "    \n",
    "    p = mdl.predict_proba(X_valid)[:,1]\n",
    "    result = -roc_auc_score(y_valid, p)\n",
    "   \n",
    "    return  -roc_auc_score(y_valid, p)\n",
    "\n",
    "space = [[int(x) for x in np.linspace(start = 10, stop = 1000, num = 10)], # Number of features to consider at every split\n",
    "         ('auto', 'sqrt'), # num_leaves\n",
    "         [int(x) for x in np.linspace(10, 120, num = 12)], # maximum number of levels allowed in each decision tree), \n",
    "         (1, 2), # minimum sample number that can be stored in a leaf node\n",
    "         (True, False)] # method used to sample data points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "f99cb21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "[1000, 'sqrt', 20, 2, True] \n",
      "\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 5.2860\n",
      "Function value obtained: -0.8928\n",
      "Current minimum: -0.8928\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "[10, 'auto', 50, 1, False] \n",
      "\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 0.0937\n",
      "Function value obtained: -0.8289\n",
      "Current minimum: -0.8928\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "[890, 'auto', 70, 1, False] \n",
      "\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 7.3582\n",
      "Function value obtained: -0.8786\n",
      "Current minimum: -0.8928\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "[10, 'sqrt', 60, 2, True] \n",
      "\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 0.0625\n",
      "Function value obtained: -0.8701\n",
      "Current minimum: -0.8928\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "[1000, 'sqrt', 90, 2, True] \n",
      "\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 5.3946\n",
      "Function value obtained: -0.8928\n",
      "Current minimum: -0.8928\n",
      "Iteration No: 6 started. Evaluating function at random point.\n",
      "[670, 'sqrt', 110, 1, False] \n",
      "\n",
      "Iteration No: 6 ended. Evaluation done at random point.\n",
      "Time taken: 5.4528\n",
      "Function value obtained: -0.8790\n",
      "Current minimum: -0.8928\n",
      "Iteration No: 7 started. Evaluating function at random point.\n",
      "[230, 'auto', 90, 2, True] \n",
      "\n",
      "Iteration No: 7 ended. Evaluation done at random point.\n",
      "Time taken: 1.2580\n",
      "Function value obtained: -0.8927\n",
      "Current minimum: -0.8928\n",
      "Iteration No: 8 started. Evaluating function at random point.\n",
      "[1000, 'sqrt', 90, 2, True] \n",
      "\n",
      "Iteration No: 8 ended. Evaluation done at random point.\n",
      "Time taken: 5.2633\n",
      "Function value obtained: -0.8928\n",
      "Current minimum: -0.8928\n",
      "Iteration No: 9 started. Evaluating function at random point.\n",
      "[780, 'auto', 10, 1, False] \n",
      "\n",
      "Iteration No: 9 ended. Evaluation done at random point.\n",
      "Time taken: 4.5111\n",
      "Function value obtained: -0.8919\n",
      "Current minimum: -0.8928\n",
      "Iteration No: 10 started. Evaluating function at random point.\n",
      "[780, 'auto', 100, 1, True] \n",
      "\n",
      "Iteration No: 10 ended. Evaluation done at random point.\n",
      "Time taken: 4.4148\n",
      "Function value obtained: -0.8879\n",
      "Current minimum: -0.8928\n"
     ]
    }
   ],
   "source": [
    "randomsearch = dummy_minimize(treinar_modelo, space, random_state=1, verbose=1, n_calls=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "b2c51648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best_parameter [1000, 'sqrt', 20, 2, True]  AUC--0.8928\n"
     ]
    }
   ],
   "source": [
    "print('Best_parameter',randomsearch .x,' AUC--0.8928')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "431294af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "[1000, 'sqrt', 20, 2, False] \n",
      "\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 7.5950\n",
      "Function value obtained: -0.8861\n",
      "Current minimum: -0.8861\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "[450, 'auto', 80, 2, True] \n",
      "\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 2.4380\n",
      "Function value obtained: -0.8927\n",
      "Current minimum: -0.8927\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "[340, 'sqrt', 60, 1, True] \n",
      "\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 1.9460\n",
      "Function value obtained: -0.8866\n",
      "Current minimum: -0.8927\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "[890, 'auto', 60, 2, True] \n",
      "\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 4.8020\n",
      "Function value obtained: -0.8927\n",
      "Current minimum: -0.8927\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "[670, 'sqrt', 20, 2, True] \n",
      "\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 3.7693\n",
      "Function value obtained: -0.8917\n",
      "Current minimum: -0.8927\n",
      "Iteration No: 6 started. Evaluating function at random point.\n",
      "[780, 'sqrt', 40, 1, True] \n",
      "\n",
      "Iteration No: 6 ended. Evaluation done at random point.\n",
      "Time taken: 4.7508\n",
      "Function value obtained: -0.8879\n",
      "Current minimum: -0.8927\n",
      "Iteration No: 7 started. Evaluating function at random point.\n",
      "[560, 'sqrt', 60, 1, False] \n",
      "\n",
      "Iteration No: 7 ended. Evaluation done at random point.\n",
      "Time taken: 4.8620\n",
      "Function value obtained: -0.8790\n",
      "Current minimum: -0.8927\n",
      "Iteration No: 8 started. Evaluating function at random point.\n",
      "[120, 'sqrt', 60, 1, True] \n",
      "\n",
      "Iteration No: 8 ended. Evaluation done at random point.\n",
      "Time taken: 0.7500\n",
      "Function value obtained: -0.8852\n",
      "Current minimum: -0.8927\n",
      "Iteration No: 9 started. Evaluating function at random point.\n",
      "[670, 'auto', 60, 1, False] \n",
      "\n",
      "Iteration No: 9 ended. Evaluation done at random point.\n",
      "Time taken: 5.7910\n",
      "Function value obtained: -0.8790\n",
      "Current minimum: -0.8927\n",
      "Iteration No: 10 started. Evaluating function at random point.\n",
      "[450, 'auto', 110, 1, True] \n",
      "\n",
      "Iteration No: 10 ended. Evaluation done at random point.\n",
      "Time taken: 3.0781\n",
      "Function value obtained: -0.8877\n",
      "Current minimum: -0.8927\n",
      "Iteration No: 11 started. Searching for the next optimal point.\n",
      "[1000, 'sqrt', 120, 2, True] \n",
      "\n",
      "Iteration No: 11 ended. Search finished for the next optimal point.\n",
      "Time taken: 5.9770\n",
      "Function value obtained: -0.8928\n",
      "Current minimum: -0.8928\n",
      "Iteration No: 12 started. Searching for the next optimal point.\n",
      "[10, 'auto', 120, 2, True] \n",
      "\n",
      "Iteration No: 12 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.3538\n",
      "Function value obtained: -0.8701\n",
      "Current minimum: -0.8928\n",
      "Iteration No: 13 started. Searching for the next optimal point.\n",
      "[10, 'auto', 120, 2, False] \n",
      "\n",
      "Iteration No: 13 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.3539\n",
      "Function value obtained: -0.8612\n",
      "Current minimum: -0.8928\n",
      "Iteration No: 14 started. Searching for the next optimal point.\n",
      "[10, 'auto', 120, 1, False] \n",
      "\n",
      "Iteration No: 14 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.4740\n",
      "Function value obtained: -0.8289\n",
      "Current minimum: -0.8928\n",
      "Iteration No: 15 started. Searching for the next optimal point.\n",
      "[780, 'sqrt', 10, 2, True] \n",
      "\n",
      "Iteration No: 15 ended. Search finished for the next optimal point.\n",
      "Time taken: 4.0340\n",
      "Function value obtained: -0.8951\n",
      "Current minimum: -0.8951\n",
      "Iteration No: 16 started. Searching for the next optimal point.\n",
      "[780, 'sqrt', 10, 2, True] \n",
      "\n",
      "Iteration No: 16 ended. Search finished for the next optimal point.\n",
      "Time taken: 3.9000\n",
      "Function value obtained: -0.8951\n",
      "Current minimum: -0.8951\n",
      "Iteration No: 17 started. Searching for the next optimal point.\n",
      "[10, 'auto', 10, 1, False] \n",
      "\n",
      "Iteration No: 17 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.4450\n",
      "Function value obtained: -0.8845\n",
      "Current minimum: -0.8951\n",
      "Iteration No: 18 started. Searching for the next optimal point.\n",
      "[10, 'auto', 10, 1, True] \n",
      "\n",
      "Iteration No: 18 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.4319\n",
      "Function value obtained: -0.8814\n",
      "Current minimum: -0.8951\n",
      "Iteration No: 19 started. Searching for the next optimal point.\n",
      "[1000, 'sqrt', 10, 2, True] \n",
      "\n",
      "Iteration No: 19 ended. Search finished for the next optimal point.\n",
      "Time taken: 5.0498\n",
      "Function value obtained: -0.8956\n",
      "Current minimum: -0.8956\n",
      "Iteration No: 20 started. Searching for the next optimal point.\n",
      "[1000, 'auto', 10, 2, True] \n",
      "\n",
      "Iteration No: 20 ended. Search finished for the next optimal point.\n",
      "Time taken: 5.0120\n",
      "Function value obtained: -0.8956\n",
      "Current minimum: -0.8956\n",
      "Iteration No: 21 started. Searching for the next optimal point.\n",
      "[1000, 'auto', 10, 2, True] \n",
      "\n",
      "Iteration No: 21 ended. Search finished for the next optimal point.\n",
      "Time taken: 4.8640\n",
      "Function value obtained: -0.8956\n",
      "Current minimum: -0.8956\n",
      "Iteration No: 22 started. Searching for the next optimal point.\n",
      "[1000, 'sqrt', 90, 2, True] \n",
      "\n",
      "Iteration No: 22 ended. Search finished for the next optimal point.\n",
      "Time taken: 5.8220\n",
      "Function value obtained: -0.8928\n",
      "Current minimum: -0.8956\n",
      "Iteration No: 23 started. Searching for the next optimal point.\n",
      "[1000, 'auto', 10, 2, True] \n",
      "\n",
      "Iteration No: 23 ended. Search finished for the next optimal point.\n",
      "Time taken: 4.7989\n",
      "Function value obtained: -0.8956\n",
      "Current minimum: -0.8956\n",
      "Iteration No: 24 started. Searching for the next optimal point.\n",
      "[1000, 'auto', 10, 2, True] \n",
      "\n",
      "Iteration No: 24 ended. Search finished for the next optimal point.\n",
      "Time taken: 4.7710\n",
      "Function value obtained: -0.8956\n",
      "Current minimum: -0.8956\n",
      "Iteration No: 25 started. Searching for the next optimal point.\n",
      "[1000, 'auto', 10, 2, True] \n",
      "\n",
      "Iteration No: 25 ended. Search finished for the next optimal point.\n",
      "Time taken: 4.7360\n",
      "Function value obtained: -0.8956\n",
      "Current minimum: -0.8956\n",
      "Iteration No: 26 started. Searching for the next optimal point.\n",
      "[1000, 'auto', 10, 2, True] \n",
      "\n",
      "Iteration No: 26 ended. Search finished for the next optimal point.\n",
      "Time taken: 4.8553\n",
      "Function value obtained: -0.8956\n",
      "Current minimum: -0.8956\n",
      "Iteration No: 27 started. Searching for the next optimal point.\n",
      "[1000, 'auto', 10, 2, True] \n",
      "\n",
      "Iteration No: 27 ended. Search finished for the next optimal point.\n",
      "Time taken: 5.0170\n",
      "Function value obtained: -0.8956\n",
      "Current minimum: -0.8956\n",
      "Iteration No: 28 started. Searching for the next optimal point.\n",
      "[10, 'sqrt', 10, 2, True] \n",
      "\n",
      "Iteration No: 28 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.4323\n",
      "Function value obtained: -0.8915\n",
      "Current minimum: -0.8956\n",
      "Iteration No: 29 started. Searching for the next optimal point.\n",
      "[10, 'auto', 50, 2, False] \n",
      "\n",
      "Iteration No: 29 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.3938\n",
      "Function value obtained: -0.8612\n",
      "Current minimum: -0.8956\n",
      "Iteration No: 30 started. Searching for the next optimal point.\n",
      "[1000, 'sqrt', 10, 1, False] \n",
      "\n",
      "Iteration No: 30 ended. Search finished for the next optimal point.\n",
      "Time taken: 6.0799\n",
      "Function value obtained: -0.8923\n",
      "Current minimum: -0.8956\n"
     ]
    }
   ],
   "source": [
    "bayessche_Optimierung = gp_minimize(treinar_modelo, space, random_state=1, verbose=1, n_calls=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "22b77a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best_parameter [1000, 'sqrt', 10, 2, True]  AUC--0.8956\n"
     ]
    }
   ],
   "source": [
    "print('Best_parameter',bayessche_Optimierung.x,' AUC--0.8956') #Best_parameter [1000, 'sqrt', 20, 2, True]  AUC--0.8928"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6a2f47",
   "metadata": {},
   "source": [
    "### Modell Bewertung\n",
    "\n",
    "In diesem Fall wird das Modell mit wiederholter geschichteter 10-facher Kreuzvalidierung auf dem Datensatz evaluieren.Hier wird die **RepeatedStratifiedKFold** verwendet damit das Modell robust trainiert und die Prozentsatz der Proben für jede Klasse beibehalten wird.\n",
    "Das Model wird dann mit dem verschidene Hyperparameter gestet. Weil die Datenset umbalaciernt sind, wird das Model mit der Metrik f1_weighted ausgewertet, die parameter average wird auf **'micro'** eingesestz. Der Micro F1-Score ist die normale F1-Formel, wird jedoch anhand der Gesamtzahl der True Positives (TP), False Positives (FP) und False Negatives (FN) berechnet, anstatt einzeln für jede Klasse.\n",
    "\n",
    "\n",
    "Das best Ergebnissen war eine Scoring von 0.856.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "122f8aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.811\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.842\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.835\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.823\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.834\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8398398398398399\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8368368368368369\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8398398398398399\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8348348348348348\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8788788788788788\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.827\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.849\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.847\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.8370000000000001\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.841\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8268268268268268\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8258258258258259\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8298298298298299\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8378378378378378\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8268268268268268\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.8399999999999999\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.8599999999999999\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.844\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.815\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.843\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8298298298298299\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8378378378378378\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8348348348348348\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8338338338338338\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8398398398398399\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.845\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.834\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.849\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.848\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.832\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8338338338338338\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.821821821821822\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8368368368368369\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8588588588588588\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8038038038038037\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.8370000000000001\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.831\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.835\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.842\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.836\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8388388388388389\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8338338338338338\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8488488488488487\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8418418418418419\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8328328328328328\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.842\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.83\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.834\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.844\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.847\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8368368368368369\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8328328328328328\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8478478478478478\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8238238238238238\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8328328328328328\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.81\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.852\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.841\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.8599999999999999\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.81\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8388388388388389\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8508508508508509\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8398398398398399\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.821821821821822\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8378378378378378\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.818\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.843\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.859\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.833\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.832\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8578578578578578\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8098098098098098\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8288288288288288\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8288288288288288\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8338338338338338\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.847\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.839\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.836\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.827\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.825\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8298298298298299\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8428428428428427\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8448448448448449\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8278278278278278\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8418418418418419\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.823\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.843\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.849\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.843\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.834\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8318318318318318\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8268268268268268\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8408408408408409\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8358358358358359\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8398398398398399\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resultado_mini = []\n",
    "num_folds = 10\n",
    "scoring = \"f1_weighted\" #This is suitable for imbalanced classes\n",
    "\n",
    "\n",
    "#kfold = StratifiedKFold(n_splits=num_folds, random_state=SEED, shuffle = True)\n",
    "kfold = RepeatedStratifiedKFold(n_splits=num_folds, n_repeats=10, random_state=SEED)\n",
    "#kfold = RepeatedKFold(n_splits=10, n_repeats=5, random_state=1)\n",
    "    \n",
    "\n",
    "for linhas_train, linhas_valid in kfold.split(X,y):\n",
    "    print('zeile_train',linhas_train.shape[0])\n",
    "    print('zeile_valid',linhas_valid.shape[0])\n",
    "\n",
    "    X_train, X_valid = X.iloc[linhas_train],X.iloc[linhas_valid]\n",
    "    y_train, y_valid = y.iloc[linhas_train],y.iloc[linhas_valid]\n",
    "\n",
    "    model_minimize = RandomForestClassifier(n_estimators=1000, n_jobs=-1, random_state=SEED, max_features='sqrt', \n",
    "                                   max_depth=10,  min_samples_leaf=2,bootstrap=True, class_weight='balanced')\n",
    "    model_minimize.fit(X_train,y_train)\n",
    "\n",
    "    p = model_minimize.predict( X_valid)\n",
    "    acc = f1_score(y_valid, p, average='micro')\n",
    "    #cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    #cv_results = cross_val_score(model, X, y, cv=kfold, scoring=scoring, n_jobs = -1)\n",
    "\n",
    "\n",
    "    \n",
    "    print(\"f1_score:\", acc)\n",
    "    print()\n",
    "\n",
    "\n",
    "    resultado_mini.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "0982720f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8400019131177104"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(resultado_mini)# Best_parameter [1000, 'sqrt', 10, 2, True] 0.836477897897898"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "78a08888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.833\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.857\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.855\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.845\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.856\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8498498498498499\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8658658658658659\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8518518518518519\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8558558558558559\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8848848848848849\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.847\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.861\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.868\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.853\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.856\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8528528528528528\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8408408408408409\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.856856856856857\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8678678678678678\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8458458458458459\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.852\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.882\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.863\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.839\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.861\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8498498498498499\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.854854854854855\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8628628628628628\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.854854854854855\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8558558558558559\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.864\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.85\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.864\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.867\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.848\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8578578578578578\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8488488488488487\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8558558558558559\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8748748748748749\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8318318318318318\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.8619999999999999\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.857\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.851\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.8619999999999999\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.844\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.856856856856857\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8488488488488487\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8708708708708709\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8508508508508509\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.856856856856857\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.861\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.859\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.856\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.861\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.854\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8618618618618619\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8558558558558559\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8638638638638638\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8518518518518519\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8518518518518519\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.836\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.868\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.861\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.864\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.852\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8608608608608609\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.856856856856857\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8578578578578578\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8478478478478478\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8638638638638638\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.844\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.847\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.8729999999999999\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.854\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.85\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8778778778778779\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8518518518518519\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.854854854854855\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8438438438438438\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8668668668668668\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.857\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.864\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.864\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.8459999999999999\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.854\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8438438438438438\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8618618618618619\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.856856856856857\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8528528528528528\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8658658658658659\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.843\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.869\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.863\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.8599999999999999\n",
      "\n",
      "zeile_train 8995\n",
      "zeile_valid 1000\n",
      "f1_score: 0.859\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.854854854854855\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8558558558558559\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.854854854854855\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8538538538538538\n",
      "\n",
      "zeile_train 8996\n",
      "zeile_valid 999\n",
      "f1_score: 0.8718718718718719\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resultado_dummy = []\n",
    "num_folds = 10\n",
    "scoring = \"f1_weighted\" #This is suitable for imbalanced classes\n",
    "#'balanced_subsample'\n",
    "\n",
    "#kfold = StratifiedKFold(n_splits=num_folds, random_state=SEED, shuffle = True)\n",
    "#kfold = RepeatedKFold(n_splits=10, n_repeats=5, random_state=1)\n",
    "kfold = RepeatedStratifiedKFold(n_splits=num_folds, n_repeats=10, random_state=SEED)\n",
    "\n",
    "   \n",
    "\n",
    "for linhas_train, linhas_valid in kfold.split(X,y):\n",
    "    print('zeile_train',linhas_train.shape[0])\n",
    "    print('zeile_valid',linhas_valid.shape[0])\n",
    "\n",
    "    X_train, X_valid = X.iloc[linhas_train],X.iloc[linhas_valid]\n",
    "    y_train, y_valid = y.iloc[linhas_train],y.iloc[linhas_valid]\n",
    "\n",
    "    model_dummy = RandomForestClassifier(n_estimators=1000, n_jobs=-1, random_state=SEED, max_features='sqrt', \n",
    "                                   max_depth=20,  min_samples_leaf=2,bootstrap=True, class_weight='balanced')\n",
    "    model_dummy.fit(X_train,y_train)\n",
    "\n",
    "    p = model_dummy.predict(X_valid)\n",
    "    acc = f1_score(y_valid, p, average= 'micro')\n",
    "    #cv_results = cross_val_score(model, X, y, cv=kfold, scoring=scoring, n_jobs = -1)'weighted'\n",
    "\n",
    "    \n",
    "    print(\"f1_score:\", acc)\n",
    "    print()\n",
    "    \n",
    "    resultado_dummy.append(acc)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "be2a5c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8566084484484483"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(resultado_dummy)#0.8569315942629286 0.8513225244122221,0.8566084484484483 Best_parameter [1000, 'sqrt', 10, 2, True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c2a60f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid , y_train, y_valid = train_test_split( X, y, test_size=0.6,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ef5b4fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "cfm_raw = plot_confusion_matrix(model_dummy,X, y, values_format = '') # add normalize = 'true' for precision matrix or 'pred' for recall matrix\n",
    "plt.savefig(\"cfm_raw.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "74d154d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7dac73ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid , y_train, y_valid = train_test_split( X, y, test_size=0.6, random_state=SEED,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "919fd244",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dummy = RandomForestClassifier(n_estimators=1000, n_jobs=-1, random_state=SEED, max_features='sqrt', \n",
    "                                   max_depth=20,  min_samples_leaf=2,bootstrap=True, class_weight='balanced')\n",
    "model_dummy.fit(X_train,y_train)\n",
    "\n",
    "p = model_dummy.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6fdbd301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.93      0.89      0.91      5012\n",
      "     class 1       0.55      0.68      0.61       985\n",
      "\n",
      "    accuracy                           0.86      5997\n",
      "   macro avg       0.74      0.79      0.76      5997\n",
      "weighted avg       0.87      0.86      0.86      5997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['class 0', 'class 1']\n",
    "print(classification_report(p, y_valid, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da8854b",
   "metadata": {},
   "source": [
    "###  Precision-Recall \n",
    "\n",
    "\n",
    "Beispiel für eine Precision-Recall-Metrik zur Bewertung der Ausgabequalität des Klassifikators.\n",
    "\n",
    "Precision-Recall ist ein nützliches Maß für den Erfolg der Vorhersage, wenn die Klassen sehr unausgewogen sind. Beim  der Precisiont ein Maß für die Relevanz der Ergebnisse, während die Recall ein Maß dafür ist, wie viele wirklich relevante Ergebnisse zurückgegeben werden.\n",
    "\n",
    "Die Precision-Recall-Kurve zeigt den Kompromiss zwischen Precision und Recall für verschiedene Schwellenwerte. Ein hoher Bereich unter der Kurve stellt sowohl eine hohe Recall als auch eine hohe Präzision dar, wobei sich eine hohe Präzision auf eine niedrige Falsch-Positiv-Rate und eine hohe Recall auf eine niedrige Falsch-Negativ-Rate bezieht. Hohe Punktzahlen für beide zeigen, dass der Klassifikator genaue Ergebnisse (hohe Präzision) sowie die Mehrheit aller positiven Ergebnisse (hohe Erinnerung) zurückgibt.\n",
    "\n",
    "Ein System mit hoher Recall, aber geringer Precision gibt viele Ergebnisse zurück, aber die meisten seiner vorhergesagten Bezeichnungen sind im Vergleich zu den Trainingsbezeichnungen falsch. Ein System mit hoher Präzision, aber geringem Recall ist genau das Gegenteil, es gibt nur sehr wenige Ergebnisse zurück, aber die meisten seiner vorhergesagten Bezeichnungen sind im Vergleich zu den Trainingsbezeichnungen korrekt. Ein ideales System mit hoher Präzision und hoher Recall liefert viele Ergebnisse, wobei alle Ergebnisse korrekt beschriftet sind.\n",
    "\n",
    "PRC-Interpretation\n",
    "1. Am niedrigsten Punkt, dh bei (0, 0) – wird die Schwelle auf 1,0 gesetzt. Das bedeutet, dass unser Modell keinen Unterschied zwischen Kunden, die Abwander werden oder nicht.\n",
    "2. Am höchsten Punkt, dh bei (1, 1), wird die Schwelle auf 0,0 gesetzt. Das bedeutet, dass unsere Präzision und Erinnerung hoch sind und das Modell perfekt Unterscheidungen treffen kann.\n",
    "3. Der Rest der Kurve sind die Werte von Precision und Recall für die Schwellenwerte zwischen 0 und 1. Unser Ziel ist es, die Kurve so nah wie möglich an (1, 1) zu bringen, was eine gute Precision und Recall bedeutet.\n",
    "4. Ähnlich wie bei ROC ist die Fläche mit der Kurve und den Achsen als Grenzen die Fläche unter der Kurve (AUC). Betrachten Sie diesen Bereich als Maß für ein gutes Modell. Die AUC reicht von 0 bis 1. Daher sollten wir einen hohen AUC-Wert anstreben. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "8581e9d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "\n",
    "display = PrecisionRecallDisplay.from_estimator(\n",
    "    model_dummy, X, y, name=\"RandomForestClassifier\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "5139c9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, SelectPercentile\n",
    "from sklearn.metrics import mean_absolute_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5234cc96",
   "metadata": {},
   "source": [
    "### Features Selection\n",
    "\n",
    "Es gibt drei Methoden um eine Feature Selection durchzuführen\n",
    "\n",
    "**1.Filter Methods**\n",
    "\n",
    "**2. Wrapper Methods**\n",
    "\n",
    "**3. Embedded Methods**\n",
    "\n",
    "\n",
    "Die wichtigsten Gründe für die Verwendung der Features Selection sind:\n",
    "\n",
    "- Es ermöglicht dem maschinellen Lernalgorithmus, schneller zu trainieren.\n",
    "- Es reduziert die Komplexität eines Modells und erleichtert dessen Interpretation.\n",
    "- Es verbessert die Genauigkeit eines Modells, wenn die richtige Teilmenge ausgewählt wird.\n",
    "- Es reduziert die Überanpassung.\n",
    "\n",
    "1. Filtermethoden werden im Allgemeinen als Vorverarbeitungsschritt verwendet. Die Auswahl der Features ist unabhängig vom Modell. Stattdessen werden Merkmale auf der Grundlage ihrer Ergebnisse in verschiedenen statistischen Tests für ihre Korrelation mit der Ergebnisvariablen ausgewählt. Die Korrelation ist hier ein subjektiver Begriff. Als grundlegende Anleitung können Sie sich auf die folgende Tabelle zum Definieren von Korrelationskoeffizienten beziehen.\n",
    "\n",
    "![Haöllpo](bild/FS1.png)\n",
    "\n",
    "\n",
    "2. Bei Wrapper-Methoden versuche ich, eine Teilmenge von Funktionen zu verwenden und ein Modell damit zu trainieren. Basierend auf den Schlussfolgerungen, die wir aus dem vorherigen Modell ziehen, entscheide ich, Features zu ihrer Teilmenge hinzuzufügen oder daraus zu entfernen. Das Problem wird im Wesentlichen auf ein Suchproblem reduziert. Diese Verfahren sind in der Regel sehr rechenintensiv. Einige gängige Beispiele für Wrapper-Methoden sind Vorwärts-Feature-Auswahl, Rückwärts-Feature-Eliminierung und Rekursive-Feature-Eliminierung .\n",
    "\n",
    "\n",
    "3. Eingebettete Methoden kombinieren die Qualitäten von Filter- und Wrapper-Methoden. Es wird von Algorithmen implementiert, die über eigene integrierte Methoden zur Merkmalsauswahl verfügen. Einige der beliebtesten Beispiele für diese Methoden sind die LASSO- und RIDGE-Regression, die über eingebaute Bestrafungsfunktionen verfügen, um eine Überanpassung zu reduzieren. Die Lasso-Regression führt eine L1-Regularisierung durch, die eine Strafe hinzufügt, die dem absoluten Wert der Größe der Koeffizienten entspricht. Die Ridge-Regression führt eine L2-Regularisierung durch, die eine Strafe hinzufügt, die dem Quadrat der Größe der Koeffizienten entspricht.\n",
    "\n",
    "**Unterschied zwischen Filter- und Wrapper-Methoden**\n",
    "\n",
    "1. Filtermethoden messen die Relevanz von Merkmalen anhand ihrer Korrelation mit abhängigen Variablen, während Wrapper-Methoden die Nützlichkeit einer Teilmenge von Merkmalen messen, indem sie tatsächlich ein Modell darauf trainieren.\n",
    "2. Filtermethoden sind im Vergleich zu Wrapper-Methoden viel schneller, da sie kein Training der Modelle beinhalten. Andererseits sind Wrapper-Methoden auch sehr rechenintensiv.\n",
    "3. Filtermethoden verwenden statistische Methoden zur Bewertung einer Teilmenge von Merkmalen, während Wrapper-Methoden eine Kreuzvalidierung verwenden.\n",
    "4. Filtermethoden können in vielen Fällen nicht die beste Teilmenge von Merkmalen finden, aber Wrapper-Methoden können immer die beste Teilmenge von Merkmalen bereitstellen.\n",
    "5. Die Verwendung der Teilmenge von Merkmalen aus den Wrapper-Methoden macht das Modell anfälliger für eine Überanpassung im Vergleich zur Verwendung einer Teilmenge von Merkmalen aus den Filtermethoden.\n",
    "\n",
    "**In diesem Fall habe ich die Filter-Methode verwendet.**\n",
    "\n",
    "Mit der Methode SelectKBest wird p-Wert mit den Parameter f_classif berechnet. Der p-Wert gibt an, wie das Signifikanzniveau von jeden Features unter sich und ihrer Beziehung zum Target ausfällt. K ist die Zahl von Features.\n",
    "Nacher wird es berechnet, welche Merkmalen (Features) nach Wichtigkeitsgewichten ausgewählt werden.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "442f21a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid , y_train, y_valid = train_test_split( X, y, test_size=0.5, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "28d0599b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1 -MAE = 0.2676338169084542\n",
      "k = 2 -MAE = 0.2688010672002668\n",
      "k = 3 -MAE = 0.255794563948641\n",
      "k = 4 -MAE = 0.20543605135901283\n",
      "k = 5 -MAE = 0.21527430381857596\n",
      "k = 6 -MAE = 0.21577455394363848\n",
      "k = 7 -MAE = 0.21860930465232617\n",
      "k = 8 -MAE = 0.2194430548607637\n",
      "k = 9 -MAE = 0.1617475404368851\n",
      "k = 10 -MAE = 0.15557778889444723\n",
      "k = 11 -MAE = 0.14307153576788395\n",
      "k = 12 -MAE = 0.14207103551775888\n",
      "k = 13 -MAE = 0.14107053526763383\n"
     ]
    }
   ],
   "source": [
    "k_vs_score = []\n",
    "\n",
    "for k in range(1,14):\n",
    "    \n",
    "    selector = SelectKBest(score_func= f_classif, k=k)\n",
    "    X_train2 = selector.fit_transform(X_train,y_train)\n",
    "    Xval2 = selector.transform(X_valid)\n",
    "\n",
    "    mdl = model_dummy\n",
    "    mdl.fit(X_train2, y_train)\n",
    "\n",
    "    p = mdl.predict(Xval2)\n",
    "\n",
    "    score = mean_absolute_error(y_valid, p)\n",
    "\n",
    "    print('k = {} -MAE = {}'.format(k,score)) \n",
    "    \n",
    "    k_vs_score.append(score)\n",
    " \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b31a80",
   "metadata": {},
   "source": [
    "- Die X Achse sind die mean_absolute_error\n",
    "- Die Y Achse sind die Anzahl von Parameter\n",
    "\n",
    "\n",
    "Die beste Zahl ist, wo die Kurve ohne Maximuns oder Miminun Punkten stabil ist . In diesem Fall ab 11. Parameter.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "789bdfbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(k_vs_score, index=range(1,14)).plot(figsize = (10,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b40c0f2",
   "metadata": {},
   "source": [
    "**Welche Spalten sind die Wichtigen ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cdda0742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts',\n",
       "       'IsActiveMember', 'EstimatedSalary', 'Female', 'Male', 'France',\n",
       "       'Spain', 'Germany'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector = SelectKBest(score_func= f_classif, k=12)\n",
    "selector.fit(X_train,y_train)\n",
    "mask = selector.get_support()\n",
    "X_valid.columns[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "716c4f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(selector.scores_, index=X_train.columns).sort_values( ascending=True).tail(5).plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41ac432",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1188b69",
   "metadata": {},
   "source": [
    "### Nächste Schritte:\n",
    "\n",
    "- **Voting-Ensemble-Klassifikator**: Beim Ensemble-Schätzer geht es darum, daß mehrere Modelle trainiert und dann die Ergebnisse für eine robustere Vorhersage aggregiert werden.\n",
    "\n",
    "\n",
    "- **Error Analysis**: Bei der Error Analysis vergleicht man die Prediction und die Wahrenwert. Die Spalten, die das Modell fehlerhaft war, werden dann isoliert. Mit diesen beiden Spalten werden nach Muster auf die Features untersucht, um herauszufinden, wo (Welche Features) das Modell fehlerhaft ist.\n",
    "\n",
    "\n",
    "- **Gruppierung von Features ausprobieren**: Hier kann Kombinationen von Features in das Modell ausprobiert werden, um ein besseres Scoring zu bekommen.\n",
    "\n",
    "\n",
    "- **Gradient Boosting**: Gradient Boosting ist Aufgrund seiner Lernmethode für die Modellierung unausgeglichener Datensätzen gut geeignet. Der Prozess läuft hier sequentiell ab. Jedes Mal, wenn eine falsche Vorhersage gemacht wurde, wird der Fokus auf die falsche vorhergesagte Beobachtung gelegt.\n",
    "\n",
    "\n",
    "- **Resampling durch Over- oder Undersampling**: Die Anzahl der Instanzen jeder Klasse so anzupassen, dass sie ausgeglichen sind. Beim Undersampling werden Instanzen der überrepräsentierten Klasse entfernt. Beim Oversampling werden synthetische Instanzen dem Trainingsdatensatz hinzugefügt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327eb25f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
